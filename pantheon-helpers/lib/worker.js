// Generated by IcedCoffeeScript 1.8.0-c
(function() {
  var Promise, clone, follow, logger, sortErrorResults, utils, x, _;

  _ = require('underscore');

  follow = require('follow');

  utils = require('./utils');

  Promise = require('promise');

  logger = require('./loggers').worker;

  x = {};

  clone = function(obj) {
    var newClone;
    newClone = JSON.parse(JSON.stringify(obj));
    return newClone;
  };

  x.get_handlers = function(handlers, entry, doc_type) {

    /*
    return a hash of {null: handler}, where handler is the handler
    for the entry/doc type combo.
    
    you can subclass this function to return an arbitrary 
    number of key/handler names. (see, e.g., get_resource_handlers)
     */
    var handler, _ref;
    handler = (_ref = handlers[doc_type]) != null ? _ref[entry.a] : void 0;
    if (handler) {
      return {
        "null": handler
      };
    } else {
      return {};
    }
  };

  x.get_plugin_handlers = function(handlers, entry, doc_type) {

    /*
    return a hash of {resource: handler} for each resource that
    has specified a handler for this entry's action.
     */
    var entry_plugin, filtered_handlers, handler, plugin, plugin_handlers, _ref, _ref1, _ref2, _ref3, _ref4;
    filtered_handlers = {};
    for (plugin in handlers) {
      plugin_handlers = handlers[plugin];
      handler = (_ref = plugin_handlers[doc_type]) != null ? _ref[entry.a] : void 0;
      if (!handler) {
        entry_plugin = entry.plugin || entry.resource;
        if (entry_plugin === plugin) {
          handler = (_ref1 = plugin_handlers[doc_type]) != null ? (_ref2 = _ref1.self) != null ? _ref2[entry.a] : void 0 : void 0;
        } else {
          handler = (_ref3 = plugin_handlers[doc_type]) != null ? (_ref4 = _ref3.other) != null ? _ref4[entry.a] : void 0 : void 0;
        }
      }
      if (handler) {
        filtered_handlers[plugin] = handler;
      }
    }
    return filtered_handlers;
  };

  x.get_audit_entries_to_sync = function(doc) {
    var now;
    now = +new Date();
    return _.filter(doc.audit, function(entry) {
      var _ref;
      return !entry.synced && ((!((_ref = entry.attempts) != null ? _ref.length : void 0)) || entry.attempts[0] < now);
    });
  };

  x.get_next_attempt_time = function(now, attempts) {
    var nextInMilliseconds, nextInMinutes;
    nextInMinutes = Math.pow(2, attempts.length);
    nextInMilliseconds = nextInMinutes * 60 * 1000;
    return now + nextInMilliseconds;
  };

  x.update_document_with_worker_result = function(doc) {
    return function(result) {
      var data_path, existing_data, new_data, _ref, _ref1, _ref2, _ref3;
      data_path = ((_ref = result.value) != null ? _ref.path : void 0) || ((_ref1 = result.error) != null ? _ref1.path : void 0);
      new_data = ((_ref2 = result.value) != null ? _ref2.data : void 0) || ((_ref3 = result.error) != null ? _ref3.data : void 0);
      if (new_data && data_path) {
        existing_data = utils.mk_objs(doc, data_path, {});
        return _.extend(existing_data, new_data);
      }
    };
  };

  x.update_audit_entry = function(doc) {
    return function(entry_results, entry_id) {
      var entry, synced;
      entry = _.findWhere(doc.audit, {
        id: entry_id
      });
      synced = _.all(entry_results, function(result) {
        return result.state === 'resolved';
      });
      entry.synced = entry.synced || synced;
      if (entry.synced) {
        delete entry.attempts;
      } else {
        entry.attempts = entry.attempts || [];
        entry.attempts.unshift(x.get_next_attempt_time(+(new Date), entry.attempts));
      }
      return _.each(entry_results, x.update_document_with_worker_result(doc));
    };
  };

  x.update_audit_entries = function(db, doc_id, results) {
    var get_doc, insert_doc;
    get_doc = Promise.denodeify(db.get).bind(db);
    insert_doc = Promise.denodeify(db.insert).bind(db);
    return get_doc(doc_id).then(function(doc) {
      var old_doc;
      old_doc = clone(doc);
      _.each(results, x.update_audit_entry(doc));
      if (_.isEqual(old_doc, doc)) {
        return Promise.resolve();
      } else {
        return insert_doc(doc)["catch"](function(err) {
          if (err.status_code === 409) {
            return x.update_audit_entries(db, doc_id, doc_type, results);
          } else {
            return Promise.reject(err);
          }
        });
      }
    });
  };

  x.on_change = function(logger, db, handlers, get_doc_type, get_handlers) {
    return function(change) {
      var doc, docLog, doc_type, entry_promises, unsynced_audit_entries;
      doc = change.doc;
      doc_type = get_doc_type(doc);
      unsynced_audit_entries = x.get_audit_entries_to_sync(doc);
      docLog = logger.child({
        docId: doc._id,
        rev: doc._rev
      });
      if (!unsynced_audit_entries.length) {
        docLog.info({
          unsyncedActions: unsynced_audit_entries
        }, 'skip handling actions');
        return;
      }
      docLog.info({
        unsyncedActions: unsynced_audit_entries
      }, 'start handling actions');
      entry_promises = {};
      _.each(unsynced_audit_entries, function(entry) {
        var actionLog, entry_handlers, handler_promises;
        entry_handlers = get_handlers(handlers, entry, doc_type);
        handler_promises = {};
        actionLog = docLog.child({
          actionId: entry.id,
          actionType: entry.a
        });
        actionLog.info({
          event: 'onChange',
          handlers: _.keys(entry_handlers)
        }, 'start running action handlers');
        _.each(entry_handlers, function(handler, handlerName) {
          var handlerLog;
          handlerLog = actionLog.child({
            handlerName: handlerName
          });
          return handler_promises[handlerName] = handler(clone(entry), clone(doc), handlerLog);
        });
        return entry_promises[entry.id] = Promise.hashResolveAll(handler_promises);
      });
      return Promise.hashAll(entry_promises).then(function(results) {
        return x.update_audit_entries(db, doc._id, results).then(function() {
          var failed, succeeded;
          failed = 0;
          succeeded = 0;
          _.each(results, function(actionResults, actionId) {
            var actionLog, rejected, resolved, _ref;
            _ref = sortErrorResults(actionResults), resolved = _ref[0], rejected = _ref[1];
            actionLog = docLog.child({
              actionId: actionId
            });
            if (_.isEmpty(rejected)) {
              actionLog.info({
                succeeded: resolved
              }, 'finish running handlers');
              return succeeded++;
            } else {
              actionLog.error({
                failed: rejected,
                succeeded: resolved
              }, 'finish running handlers');
              return failed++;
            }
          });
          if (failed) {
            return docLog.error({
              succeeded: succeeded,
              failed: failed
            }, 'finish handling actions');
          } else {
            return docLog.info({
              succeeded: succeeded
            }, 'finish handling actions');
          }
        });
      })["catch"](function(err) {
        return docLog.error({
          error: err
        }, 'finish handling actions');
      }).then(function() {
        return Promise.resolve();
      });
    };
  };

  x.setInterval = setInterval;

  x.processFailures = function(db, onChange) {
    return function() {
      return db.view('pantheon', 'failures_by_retry_date', {
        endkey: +new Date(),
        include_docs: true
      }, 'promise').then(function(resp) {
        return Promise.all(resp.rows.map(onChange));
      });
    };
  };

  x.watchForFailures = function(db, onChange, period) {
    var interval;
    interval = x.setInterval(x.processFailures(db, onChange), period);
    return interval;
  };

  x.start_worker = function(logger, db, handlers, get_doc_type, get_handlers) {
    var MINUTES, feed, interval, onChange, opts;
    if (get_handlers == null) {
      get_handlers = x.get_handlers;
    }

    /*
    start a worker that watches a db for changes and calls the appropriate handlers.
    it also looks in the database every two minutes for failed syncs that are ready for a retry.
    db: the nano database to watch
    handlers: a hash of handlers. Each handler should handle a different action.
    get_doc_type: a function that returns the document type. this can be used to look up the appropriate handler.
    get_handlers: a function that returns the worker handlers to handle an unhandled event.
     */
    opts = {
      db: db.config.url + '/' + db.config.db,
      include_docs: true
    };
    feed = new follow.Feed(opts);
    feed.filter = function(doc, req) {
      if (doc._deleted) {
        return false;
      } else {
        return true;
      }
    };
    onChange = x.on_change(logger, db, handlers, get_doc_type, get_handlers);
    feed.on('change', onChange);
    feed.on('error', function(err) {
      return console.log(err);
    });
    logger.info('worker started');
    feed.follow();
    MINUTES = 60 * 1000;
    interval = x.watchForFailures(db, onChange, 2 * MINUTES);
    return {
      feed: feed,
      interval: interval
    };
  };

  sortErrorResults = function(actionResults) {
    var rejected, resolved;
    resolved = {};
    rejected = {};
    _.each(actionResults, function(resourceResult, resourceName) {
      if (resourceResult.state === 'resolved') {
        return resolved[resourceName] = resourceResult.value || null;
      } else {
        return rejected[resourceName] = resourceResult.error || null;
      }
    });
    return [resolved, rejected];
  };

  module.exports = x;

}).call(this);
